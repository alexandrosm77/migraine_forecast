# Promtail DaemonSet - Collects logs from all pods and sends to Loki
---
# ServiceAccount for Promtail
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: migraine-forecast

---
# ClusterRole - Promtail needs to read pod metadata from K8s API
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
rules:
- apiGroups: [""]
  resources: ["nodes", "nodes/proxy", "services", "endpoints", "pods"]
  verbs: ["get", "watch", "list"]

---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: migraine-forecast
roleRef:
  kind: ClusterRole
  name: promtail
  apiGroup: rbac.authorization.k8s.io

---
# ConfigMap for Promtail configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: migraine-forecast
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://192.168.0.11:3100/loki/api/v1/push

    scrape_configs:
      # Scrape logs from all pods in migraine-forecast namespace
      - job_name: kubernetes-pods
        static_configs:
          - targets:
              - localhost
            labels:
              job: migraine-forecast
              __path__: /var/log/pods/migraine-forecast_*/*/*.log
        pipeline_stages:
          # Parse CRI log format
          - cri: {}
          # Extract pod metadata from log path
          # Format: /var/log/pods/<namespace>_<pod-name>_<pod-uid>/<container>/<file>.log
          - regex:
              source: filename
              expression: '/var/log/pods/(?P<namespace>[^_]+)_(?P<pod>[^_]+)_[^/]+/(?P<container>[^/]+)/.*\.log'
          - labels:
              namespace:
              pod:
              container:
          # Parse JSON logs from Django application
          - json:
              expressions:
                level: level
                logger: logger
                module: module
                trace_id: trace_id
                span_id: span_id
          # Set log level as a label for filtering
          - labels:
              level:
          # Drop trace fields from log line (they're now labels)
          - labeldrop:
              - trace_id
              - span_id

---
# DaemonSet - runs one Promtail pod per node
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: migraine-forecast
  labels:
    app: promtail
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      containers:
      - name: promtail
        image: grafana/promtail:2.9.0
        args:
          - -config.file=/etc/promtail/promtail.yaml
        ports:
        - containerPort: 9080
          name: http-metrics

        volumeMounts:
        # Promtail config
        - name: config
          mountPath: /etc/promtail

        # Pod logs on the node
        - name: pods-logs
          mountPath: /var/log/pods
          readOnly: true

        # Container runtime logs (for Docker/containerd)
        - name: containers-logs
          mountPath: /var/lib/docker/containers
          readOnly: true

        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "200m"

      volumes:
      - name: config
        configMap:
          name: promtail-config

      - name: pods-logs
        hostPath:
          path: /var/log/pods

      - name: containers-logs
        hostPath:
          path: /var/lib/docker/containers

      tolerations:
      # Run on all nodes including master
      - operator: Exists
        effect: NoSchedule

