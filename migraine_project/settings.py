"""
Django settings for migraine_project project.

Generated by 'django-admin startproject' using Django 5.1.7.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.1/ref/settings/
"""

from pathlib import Path
import os
import sys
import sentry_sdk
from sentry_sdk.integrations.django import DjangoIntegration
from sentry_sdk.integrations.logging import LoggingIntegration
from forecast.__version__ import __version__ as APP_VERSION

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.1/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = "django-insecure-&t@9q8li_^kapfn=-n0j667&j6du_k*b*f1uet5iss5(^2ab-7"

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = True

ALLOWED_HOSTS = ["*"]

# CSRF settings
CSRF_TRUSTED_ORIGINS = [
    "https://8329-ic19w01kgqm2zowmagk08-51be25fc.manus.computer",
    "http://localhost:8000",
    "http://127.0.0.1:8000",
]


# Application definition

INSTALLED_APPS = [
    "django.contrib.admin",
    "django.contrib.auth",
    "django.contrib.contenttypes",
    "django.contrib.sessions",
    "django.contrib.messages",
    "django.contrib.staticfiles",
    "django_json_widget",
    "forecast",
]

MIDDLEWARE = [
    "django.middleware.security.SecurityMiddleware",
    "whitenoise.middleware.WhiteNoiseMiddleware",
    "django.contrib.sessions.middleware.SessionMiddleware",
    "django.middleware.locale.LocaleMiddleware",  # Language selection middleware
    "django.middleware.common.CommonMiddleware",
    "django.middleware.csrf.CsrfViewMiddleware",
    "django.contrib.auth.middleware.AuthenticationMiddleware",
    "forecast.middleware.UserLanguageMiddleware",  # Custom middleware for user language preference
    "django.contrib.messages.middleware.MessageMiddleware",
    "django.middleware.clickjacking.XFrameOptionsMiddleware",
]

ROOT_URLCONF = "migraine_project.urls"

TEMPLATES = [
    {
        "BACKEND": "django.template.backends.django.DjangoTemplates",
        "DIRS": [],
        "APP_DIRS": True,
        "OPTIONS": {
            "context_processors": [
                "django.template.context_processors.debug",
                "django.template.context_processors.request",
                "django.contrib.auth.context_processors.auth",
                "django.contrib.messages.context_processors.messages",
                "forecast.context_processors.version_context",
            ],
        },
    },
]

WSGI_APPLICATION = "migraine_project.wsgi.application"


# Database
# https://docs.djangoproject.com/en/5.1/ref/settings/#databases

# Support both SQLite (local dev) and PostgreSQL (production)
# Use PostgreSQL if DB_ENGINE is set, otherwise default to SQLite
DB_ENGINE = os.environ.get('DB_ENGINE', 'sqlite3')

# Check if we're running tests - always use SQLite for tests
RUNNING_TESTS = 'test' in sys.argv

if RUNNING_TESTS:
    # Always use SQLite for tests regardless of production database
    DATABASES = {
        "default": {
            "ENGINE": "django.db.backends.sqlite3",
            "NAME": BASE_DIR / "test_db.sqlite3",
        }
    }
elif DB_ENGINE == 'postgresql':
    DATABASES = {
        "default": {
            "ENGINE": "django.db.backends.postgresql",
            "NAME": os.environ.get('DB_NAME', 'migraine_forecast'),
            "USER": os.environ.get('DB_USER', 'postgres'),
            "PASSWORD": os.environ.get('DB_PASSWORD', ''),
            "HOST": os.environ.get('DB_HOST', 'localhost'),
            "PORT": os.environ.get('DB_PORT', '5432'),
            "CONN_MAX_AGE": int(os.environ.get('DB_CONN_MAX_AGE', '600')),  # Connection pooling
        }
    }
else:
    # SQLite for local development
    DATABASES = {
        "default": {
            "ENGINE": "django.db.backends.sqlite3",
            "NAME": BASE_DIR / "db.sqlite3",
        }
    }


# Password validation
# https://docs.djangoproject.com/en/5.1/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        "NAME": "django.contrib.auth.password_validation.UserAttributeSimilarityValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.MinimumLengthValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.CommonPasswordValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.NumericPasswordValidator",
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.1/topics/i18n/

LANGUAGE_CODE = "en"

# Supported languages
LANGUAGES = [
    ("en", "English"),
    ("el", "Ελληνικά"),  # Greek
]

# Path where translation files will be stored
LOCALE_PATHS = [
    BASE_DIR / "locale",
]

TIME_ZONE = "UTC"

USE_I18N = True

USE_L10N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.1/howto/static-files/

STATIC_URL = "static/"
STATIC_ROOT = BASE_DIR / "staticfiles"

# WhiteNoise configuration
STORAGES = {
    "default": {
        "BACKEND": "django.core.files.storage.FileSystemStorage",
    },
    "staticfiles": {
        "BACKEND": "whitenoise.storage.CompressedManifestStaticFilesStorage",
    },
}

# Default primary key field type
# https://docs.djangoproject.com/en/5.1/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"

# Authentication settings
LOGIN_URL = "/login/"
LOGOUT_REDIRECT_URL = "/"

# Import email settings
try:
    from .email_settings import *
except ImportError:
    pass


# Custom log filter to exclude Kubernetes health probe logs
class HealthProbeLogFilter:
    """
    Filter out Kubernetes health probe requests from logs.
    This prevents them from being sent to Sentry via LoggingIntegration.
    """
    def filter(self, record):
        # Get the log message
        message = record.getMessage()

        # Filter out logs containing kube-probe user agent
        if "kube-probe/" in message:
            return False  # Don't log this message

        return True  # Log all other messages


# Logging configuration
# LOG_FORMAT: 'text' (default, human-readable) or 'json' (structured for Promtail/Loki)
# LOG_TO_FILE: 'true' (default) or 'false' (disable file logging in Kubernetes)
LOG_FORMAT = os.getenv("LOG_FORMAT", "text").lower()
LOG_TO_FILE = os.getenv("LOG_TO_FILE", "true").lower() in ("1", "true", "yes", "on")

# Build formatters based on LOG_FORMAT
LOGGING_FORMATTERS = {
    "verbose": {
        "format": "{levelname} {asctime} {module} {message}",
        "style": "{",
    },
}

# Add JSON formatter if python-json-logger is available and JSON format is requested
if LOG_FORMAT == "json":
    try:
        from pythonjsonlogger import jsonlogger

        class SentryTraceJsonFormatter(jsonlogger.JsonFormatter):
            """
            Custom JSON formatter that includes Sentry trace context for correlation.
            This allows correlating logs with Sentry transactions in Grafana.

            Note: Sentry trace context is only available after sentry_sdk.init() is called
            and during an active transaction/span. The formatter gracefully handles cases
            where Sentry is not initialized or no span is active.
            """
            def add_fields(self, log_record, record, message_dict):
                super().add_fields(log_record, record, message_dict)
                # Add standard fields
                log_record["level"] = record.levelname.lower()
                log_record["logger"] = record.name
                log_record["module"] = record.module
                log_record["funcName"] = record.funcName
                log_record["lineno"] = record.lineno

                # Add Sentry trace context if available
                # This uses sentry_sdk which is imported at the top of settings.py
                # The trace context is only available during an active transaction
                try:
                    scope = sentry_sdk.get_current_scope()
                    span = scope.span if scope else None
                    if span:
                        log_record["trace_id"] = span.trace_id
                        log_record["span_id"] = span.span_id
                        if span.parent_span_id:
                            log_record["parent_span_id"] = span.parent_span_id
                except Exception:
                    pass  # Sentry not initialized or no active span

        LOGGING_FORMATTERS["json"] = {
            "()": SentryTraceJsonFormatter,
            "format": "%(asctime)s %(levelname)s %(name)s %(message)s",
            "datefmt": "%Y-%m-%dT%H:%M:%S%z",
        }
    except ImportError:
        # python-json-logger not installed, fall back to text format
        import logging as _logging
        _logging.warning(
            "LOG_FORMAT=json requested but python-json-logger is not installed. "
            "Falling back to text format. Install with: pip install python-json-logger"
        )
        LOG_FORMAT = "text"

# Determine which formatter to use
ACTIVE_FORMATTER = "json" if LOG_FORMAT == "json" else "verbose"

# Build handlers based on configuration
LOGGING_HANDLERS = {
    "console": {
        "level": "INFO",
        "class": "logging.StreamHandler",
        "formatter": ACTIVE_FORMATTER,
        "filters": ["health_probe_filter"],
    },
}

# Only add file handler if LOG_TO_FILE is enabled
if LOG_TO_FILE:
    LOGGING_HANDLERS["file"] = {
        "level": "INFO",
        "class": "logging.FileHandler",
        "filename": os.path.join(BASE_DIR, "migraine_forecast.log"),
        "formatter": ACTIVE_FORMATTER,
        "filters": ["health_probe_filter"],
    }

# Determine which handlers to use for loggers
ACTIVE_HANDLERS = ["console", "file"] if LOG_TO_FILE else ["console"]

LOGGING = {
    "version": 1,
    "disable_existing_loggers": False,
    "filters": {
        "health_probe_filter": {
            "()": "migraine_project.settings.HealthProbeLogFilter",
        },
    },
    "formatters": LOGGING_FORMATTERS,
    "handlers": LOGGING_HANDLERS,
    "loggers": {
        "django": {
            "handlers": ACTIVE_HANDLERS,
            "level": "INFO",
            "propagate": True,
        },
        "forecast": {
            "handlers": ACTIVE_HANDLERS,
            "level": "INFO",
            "propagate": True,
        },
        # Sentry's own logger
        "sentry_sdk": {
            "handlers": ["console"],
            "level": "ERROR",
            "propagate": False,
        },
        # Gunicorn access logs - also apply filter
        "gunicorn.access": {
            "handlers": ACTIVE_HANDLERS,
            "level": "INFO",
            "propagate": False,
            "filters": ["health_probe_filter"],
        },
    },
}

# LLM configuration (OpenAI-compatible)
LLM_ENABLED = os.getenv("LLM_ENABLED", "true").lower() in ("1", "true", "yes", "on")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "http://192.168.0.11:11434")
# LLM_MODEL = os.getenv('LLM_MODEL', 'ibm/granite4:tiny-h')
LLM_MODEL = os.getenv("LLM_MODEL", "ibm/granite4:3b-h")
LLM_API_KEY = os.getenv("LLM_API_KEY", "")
LLM_TIMEOUT = float(os.getenv("LLM_TIMEOUT", "240.0"))

# Sentry/GlitchTip configuration

# DSN for GlitchTip
# SENTRY_DSN = os.getenv("SENTRY_DSN", "http://da3f96ceb002454e85ac49a5f1916cd0@192.168.0.11:8001/1")

# DSN for Sentry
# SENTRY_DSN = "https://f29cf4ee8caca3113b2c205d277cfb9c@o4510297010733056.ingest.de.sentry.io/4510297165070417"
SENTRY_DSN = os.getenv("SENTRY_DSN", "http://a5d5bab0548d4a5f8b8701ee945ebb47@192.168.0.11:8001/1")

SENTRY_ENABLED = os.getenv("SENTRY_ENABLED", "false").lower() in ("1", "true", "yes", "on")
SENTRY_ENVIRONMENT = os.getenv("SENTRY_ENVIRONMENT", "development" if DEBUG else "production")
SENTRY_TRACES_SAMPLE_RATE = float(os.getenv("SENTRY_TRACES_SAMPLE_RATE", "1.0"))  # 1.0 = 100% of transactions
SENTRY_PROFILES_SAMPLE_RATE = float(os.getenv("SENTRY_PROFILES_SAMPLE_RATE", "1.0"))  # 1.0 = 100% of transactions


def sentry_traces_sampler(sampling_context):
    """
    Custom sampler to control which transactions are sent to Sentry.
    This is more efficient than before_send as it prevents transactions from being created at all.
    Filters out Kubernetes health probe requests.
    """
    # Get the WSGI environ from the sampling context
    wsgi_environ = sampling_context.get("wsgi_environ", {})

    # Get the path and user agent
    path = wsgi_environ.get("PATH_INFO", "")
    user_agent = wsgi_environ.get("HTTP_USER_AGENT", "")

    # Don't sample Kubernetes health check probes
    # They hit the root path "/" with user agent "kube-probe/x.xx"
    if path == "/" and user_agent.startswith("kube-probe/"):
        return 0.0  # Don't sample (0% sampling rate)

    # For all other requests, use the configured sample rate
    return SENTRY_TRACES_SAMPLE_RATE


def sentry_before_breadcrumb(crumb, hint):
    """
    Filter breadcrumbs before they are added to Sentry events.
    This prevents health probe breadcrumbs from being created at all.
    """
    # Check if this breadcrumb is related to a health probe request
    if crumb.get("category") == "httplib":
        # Check the data for kube-probe user agent
        data = crumb.get("data", {})
        if "kube-probe/" in str(data):
            return None  # Drop the breadcrumb

    # Check message for kube-probe
    message = crumb.get("message", "")
    if "kube-probe/" in message:
        return None  # Drop the breadcrumb

    return crumb  # Keep the breadcrumb


def sentry_before_send(event, hint):
    """
    Filter events before sending to Sentry.
    This is a fallback filter for events that weren't caught by the sampler.
    Also filters out health probe errors, breadcrumbs, and log messages.
    """
    # Check if this is a transaction (performance monitoring)
    if event.get("type") == "transaction":
        # Get the transaction name (URL path)
        transaction_name = event.get("transaction", "")

        # Get request data to check user agent
        request_data = event.get("request", {})
        headers = request_data.get("headers", {})
        user_agent = headers.get("User-Agent", "") or headers.get("user-agent", "")

        # Filter out health check endpoints from Kubernetes probes
        if transaction_name in ("/", "GET /") and user_agent.startswith("kube-probe/"):
            return None  # Drop the event

    # For error events, also filter out if they're from health probes
    # This prevents noise from probe-related errors
    if event.get("type") in ("error", "default"):
        request_data = event.get("request", {})
        headers = request_data.get("headers", {})
        user_agent = headers.get("User-Agent", "") or headers.get("user-agent", "")

        # Drop errors from health probes
        if user_agent.startswith("kube-probe/"):
            return None

    # Filter out breadcrumbs containing kube-probe
    breadcrumbs = event.get("breadcrumbs", {}).get("values", [])
    if breadcrumbs:
        filtered_breadcrumbs = [
            bc for bc in breadcrumbs
            if "kube-probe/" not in str(bc.get("message", ""))
            and "kube-probe/" not in str(bc.get("data", {}))
        ]
        if len(filtered_breadcrumbs) != len(breadcrumbs):
            event["breadcrumbs"]["values"] = filtered_breadcrumbs

    # Filter out log messages containing kube-probe
    # This catches any logs that weren't filtered by the logging filter
    log_entry = event.get("logentry", {})
    if log_entry:
        message = log_entry.get("message", "")
        if "kube-probe/" in message:
            return None  # Drop the event

    return event  # Send the event to Sentry


if SENTRY_ENABLED and SENTRY_DSN:
    sentry_sdk.init(
        dsn=SENTRY_DSN,
        enable_logs=True,
        integrations=[
            DjangoIntegration(
                transaction_style="url",  # Track transactions by URL pattern
                middleware_spans=True,  # Create spans for middleware
                signals_spans=True,  # Create spans for Django signals
                cache_spans=True,  # Create spans for cache operations
            ),
            LoggingIntegration(
                level=None,  # Capture all log levels
                event_level="ERROR",  # Send ERROR and above as events to Sentry
            ),
        ],
        # Use custom sampler to filter out health check transactions
        # This is more efficient than traces_sample_rate as it prevents transaction creation
        traces_sampler=sentry_traces_sampler,
        # Set profiles_sample_rate to 1.0 to profile 100% of sampled transactions
        profiles_sample_rate=SENTRY_PROFILES_SAMPLE_RATE,
        # Environment name
        environment=SENTRY_ENVIRONMENT,
        # Send default PII (Personally Identifiable Information) like user IP, user ID
        send_default_pii=True,
        # Release tracking - useful for tracking which version caused issues
        release=f"migraine-forecast@{APP_VERSION}",
        # Additional options
        debug=False,  # Disable debug mode to reduce console noise
        attach_stacktrace=True,  # Attach stacktraces to all messages
        # Request bodies
        max_request_body_size="medium",  # Capture request bodies (small/medium/always)
        # Breadcrumbs
        max_breadcrumbs=50,  # Number of breadcrumbs to keep
        before_breadcrumb=sentry_before_breadcrumb,  # Filter breadcrumbs before creation
        # Before send hook to filter/modify events before sending
        before_send=sentry_before_send,
    )

SESSION_COOKIE_NAME = "forecast_sessionid"
CSRF_COOKIE_NAME = "forecast_csrftoken"

# Celery Configuration
CELERY_BROKER_URL = os.environ.get('CELERY_BROKER_URL', 'redis://localhost:6379/0')
CELERY_RESULT_BACKEND = os.environ.get('CELERY_RESULT_BACKEND', 'redis://localhost:6379/0')
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'UTC'
CELERY_ENABLE_UTC = True
# Task routing - send LLM tasks to dedicated queue
CELERY_TASK_ROUTES = {
    'forecast.tasks.generate_prediction': {'queue': 'llm'},
    'forecast.tasks.generate_digest_predictions': {'queue': 'llm'},
}
# Default queue for all other tasks
CELERY_TASK_DEFAULT_QUEUE = 'default'
