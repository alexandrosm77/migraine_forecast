name: Kubernetes Deployment

on:
  push:
    branches: [ "main" ]

jobs:
  build:
    runs-on: self-hosted
    environment: latest
    outputs:
      version: ${{ steps.get_version.outputs.version }}
      image-digest: ${{ steps.build.outputs.digest }}
    steps:
      -
        name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      -
        name: Get current version
        id: get_version
        run: |
          VERSION=$(python3 -c "import sys; sys.path.insert(0, '.'); from forecast.__version__ import __version__; print(__version__)")
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "Building version: $VERSION"

      -
        name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      -
        name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      -
        name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      -
        name: Build and push
        id: build
        uses: docker/build-push-action@v6
        with:
          push: true
          platforms: linux/arm64
          tags: |
            alexandrosm77/migraine_forecast:latest
            alexandrosm77/migraine_forecast:${{ steps.get_version.outputs.version }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  test-linting:
    needs: build
    runs-on: self-hosted
    steps:
      -
        name: Checkout repository
        uses: actions/checkout@v4

      -
        name: Run linting checks
        run: |
          docker run --rm \
            alexandrosm77/migraine_forecast@${{ needs.build.outputs.image-digest }} \
            sh -c "pip install flake8 && flake8 forecast/ migraine_project/ --exclude=migrations,__pycache__ --max-line-length=120 --statistics"

  test-unittest:
    needs: build
    runs-on: self-hosted
    steps:
      -
        name: Checkout repository
        uses: actions/checkout@v4

      -
        name: Run unit tests in Docker container
        run: |
          docker run --rm \
            alexandrosm77/migraine_forecast@${{ needs.build.outputs.image-digest }} \
            python manage.py test forecast.tests --verbosity=2

  test-integration:
    needs: build
    runs-on: self-hosted
    steps:
      -
        name: Checkout repository
        uses: actions/checkout@v4

      -
        name: Run integration tests in Docker container
        run: |
          docker run --rm \
            alexandrosm77/migraine_forecast@${{ needs.build.outputs.image-digest }} \
            python manage.py test forecast.integration_tests --verbosity=2

  deploy:
    needs: [test-linting, test-unittest, test-integration]
    runs-on: self-hosted
    environment: latest
    # Ensure only one deployment runs at a time
    concurrency:
      group: deployment
      cancel-in-progress: false
    steps:
      -
        name: Checkout repository
        uses: actions/checkout@v4

      -
        name: Create/Update Kubernetes secrets and config
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            echo "$(date '+%Y-%m-%d %H:%M:%S') - Creating/updating Kubernetes secrets..."

            # Create namespace if it doesn't exist
            sudo kubectl create namespace migraine-forecast --dry-run=client -o yaml | sudo kubectl apply -f -

            # Create/update secret from GitHub secrets
            sudo kubectl create secret generic migraine-secrets \
              --from-literal=SENTRY_DSN="${{ secrets.SENTRY_DSN }}" \
              --from-literal=DOCKERHUB_TOKEN="${{ secrets.DOCKERHUB_TOKEN }}" \
              --namespace=migraine-forecast \
              --dry-run=client -o yaml | sudo kubectl apply -f -

            # Create/update ConfigMap
            sudo kubectl create configmap migraine-config \
              --from-literal=DJANGO_DEBUG="False" \
              --from-literal=SENTRY_ENABLED="${{ vars.SENTRY_ENABLED }}" \
              --from-literal=SENTRY_ENVIRONMENT="${{ vars.SENTRY_ENVIRONMENT }}" \
              --from-literal=SENTRY_TRACES_SAMPLE_RATE="${{ vars.SENTRY_TRACES_SAMPLE_RATE }}" \
              --from-literal=SENTRY_PROFILES_SAMPLE_RATE="${{ vars.SENTRY_PROFILES_SAMPLE_RATE }}" \
              --from-literal=DOCKERHUB_USERNAME="${{ vars.DOCKERHUB_USERNAME }}" \
              --from-literal=LOG_FORMAT="json" \
              --from-literal=LOG_TO_FILE="false" \
              --namespace=migraine-forecast \
              --dry-run=client -o yaml | sudo kubectl apply -f -

            echo "$(date '+%Y-%m-%d %H:%M:%S') - Secrets and config updated successfully"

      -
        name: Deploy infrastructure (PVs, CronJob, Promtail)
        run: |
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Deploying infrastructure..."

          # Create temporary SSH key file
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key

          # Deploy namespace, PVs, and CronJob via stdin
          cat k8s/namespace.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          cat k8s/persistent-volume.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          cat k8s/backup-cronjob.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          # Deploy Promtail for log collection
          cat k8s/promtail.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          # Restart Promtail to pick up config changes
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl rollout restart daemonset/promtail -n migraine-forecast"

          # Clean up key
          rm -f ~/.ssh/deploy_key

          echo "$(date '+%Y-%m-%d %H:%M:%S') - Infrastructure deployed"

      -
        name: Backup database
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            echo "$(date '+%Y-%m-%d %H:%M:%S') - Creating database backup..."

            # Check if database exists (skip backup on first deployment)
            if [ ! -f /home/alexandros/migraine/db.sqlite3 ]; then
              echo "$(date '+%Y-%m-%d %H:%M:%S') - No database found, skipping backup (first deployment)"
              exit 0
            fi

            # Check if PVCs are bound
            echo "Checking PVC status..."
            sudo kubectl get pvc -n migraine-forecast

            # Run backup job immediately (don't wait for scheduled time)
            JOB_NAME="migraine-backup-$(date +%s)"
            sudo kubectl create job --from=cronjob/migraine-db-backup $JOB_NAME -n migraine-forecast

            # Wait for backup to complete (max 60 seconds)
            for i in {1..12}; do
              # Check job status
              JOB_STATUS=$(sudo kubectl get job $JOB_NAME -n migraine-forecast -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' 2>/dev/null)
              JOB_FAILED=$(sudo kubectl get job $JOB_NAME -n migraine-forecast -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}' 2>/dev/null)

              if [ "$JOB_STATUS" = "True" ]; then
                echo "$(date '+%Y-%m-%d %H:%M:%S') - Backup completed successfully"
                break
              elif [ "$JOB_FAILED" = "True" ]; then
                echo "$(date '+%Y-%m-%d %H:%M:%S') - Backup job failed!"
                echo "Job logs:"
                sudo kubectl logs job/$JOB_NAME -n migraine-forecast
                echo "Pod status:"
                sudo kubectl get pods -n migraine-forecast -l job-name=$JOB_NAME
                exit 1
              fi

              echo "Waiting for backup to complete... ($i/12)"
              sleep 5
            done

            # If we got here and backup didn't complete, show debug info
            if [ "$JOB_STATUS" != "True" ]; then
              echo "$(date '+%Y-%m-%d %H:%M:%S') - Backup timed out!"
              echo "Job status:"
              sudo kubectl get job $JOB_NAME -n migraine-forecast -o yaml
              echo "Pod status:"
              sudo kubectl get pods -n migraine-forecast -l job-name=$JOB_NAME
              echo "Pod logs:"
              sudo kubectl logs -n migraine-forecast -l job-name=$JOB_NAME --all-containers=true
            fi

      -
        name: Run database migrations
        run: |
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Running database migrations..."

          # Create temporary SSH key file
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key

          # Delete old migration job if it exists
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl delete job migraine-migration -n migraine-forecast --ignore-not-found=true"

          # Apply migration job via stdin
          cat k8s/migration-job.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          # Wait for migration to complete (max 5 minutes)
          echo "Waiting for migrations to complete..."
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl wait --for=condition=complete --timeout=300s job/migraine-migration -n migraine-forecast && \
             echo '$(date '+%Y-%m-%d %H:%M:%S') - Migrations completed successfully' || \
             (echo '$(date '+%Y-%m-%d %H:%M:%S') - Error: Migrations failed!' && \
              echo '$(date '+%Y-%m-%d %H:%M:%S') - Check logs with: sudo kubectl logs -n migraine-forecast job/migraine-migration' && \
              echo '$(date '+%Y-%m-%d %H:%M:%S') - Database backup is available for manual recovery if needed' && \
              exit 1)"

          # Clean up key
          rm -f ~/.ssh/deploy_key

      -
        name: Deploy application
        run: |
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Deploying application..."

          # Create temporary SSH key file
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key

          # Delete old monolithic deployment if it exists (migration from single to split deployment)
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl delete deployment migraine-forecast -n migraine-forecast --ignore-not-found=true"

          # Deploy the application and service via stdin
          cat k8s/deployment.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          cat k8s/service.yaml | ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} "sudo kubectl apply -f -"

          # Force restart to pick up new image
          echo "Restarting deployments to pick up new image..."
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl rollout restart deployment/migraine-forecast-web -n migraine-forecast && \
             sudo kubectl rollout restart deployment/migraine-forecast-cron -n migraine-forecast"

          # Wait for web deployment to complete
          echo "Waiting for web deployment to complete..."
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl rollout status deployment/migraine-forecast-web -n migraine-forecast --timeout=300s"

          # Wait for cron deployment to complete
          echo "Waiting for cron deployment to complete..."
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "sudo kubectl rollout status deployment/migraine-forecast-cron -n migraine-forecast --timeout=300s"

          # Show status
          echo "$(date '+%Y-%m-%d %H:%M:%S') - Deployment successful!"

          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "echo '$(date '+%Y-%m-%d %H:%M:%S') - Pod status:' && \
             sudo kubectl get pods -n migraine-forecast -l app=migraine-forecast && \
             echo '' && \
             echo '$(date '+%Y-%m-%d %H:%M:%S') - Web pod logs:' && \
             sudo kubectl logs -n migraine-forecast -l component=web --tail=10 && \
             echo '' && \
             echo '$(date '+%Y-%m-%d %H:%M:%S') - Cron pod logs:' && \
             sudo kubectl logs -n migraine-forecast -l component=cron --tail=10"

          # Clean up key
          rm -f ~/.ssh/deploy_key

  cleanup:
    needs: deploy
    runs-on: self-hosted
    environment: latest
    if: always()
    steps:
      -
        name: Clean up old Kubernetes resources
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.SSH_HOST }}
          username: ${{ secrets.SSH_USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            echo "Cleaning up old migration jobs..."
            sudo kubectl delete jobs -n migraine-forecast -l job-name=migraine-migration --field-selector status.successful=1 --ignore-not-found=true

            echo "Cleaning up old backup jobs (keep last 5)..."
            sudo kubectl get jobs -n migraine-forecast -l job-name=migraine-backup-* --sort-by=.metadata.creationTimestamp -o name 2>/dev/null | head -n -5 | xargs -r sudo kubectl delete -n migraine-forecast

            echo "Kubernetes cleanup complete"

      -
        name: Clean up untagged Docker images on Pi
        continue-on-error: true
        run: |
          echo "Cleaning up untagged/dangling Docker images on Pi..."

          # Create temporary SSH key file
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key

          # Remove dangling images on Pi
          ssh -i ~/.ssh/deploy_key -o StrictHostKeyChecking=no \
            ${{ secrets.SSH_USERNAME }}@${{ secrets.SSH_HOST }} \
            "echo 'Before cleanup:' && \
             sudo docker system df && \
             echo '' && \
             echo 'Removing dangling images...' && \
             sudo docker image prune -f && \
             echo '' && \
             echo 'After cleanup:' && \
             sudo docker system df"

          # Clean up key
          rm -f ~/.ssh/deploy_key

          echo ""
          echo "Pi Docker cleanup complete"

      -
        name: Clean up inactive images in Docker Hub
        continue-on-error: true
        run: |
          echo "Cleaning up inactive images in Docker Hub registry..."

          # Docker Hub doesn't have "untagged" images like local Docker
          # But we can enable "Automated Builds Cleanup" via API
          # This requires a Personal Access Token with delete permissions

          # Note: Docker Hub automatically garbage collects unreferenced layers
          # Manual cleanup is only needed for old tags, which you want to keep

          echo "Docker Hub automatically garbage collects unreferenced image layers."
          echo "All your tagged images will be kept."
          echo ""
          echo "If you need to free up space on Docker Hub, you can:"
          echo "1. Enable 'Inactive Image Cleanup' in repository settings"
          echo "2. Manually delete old tags from: https://hub.docker.com/r/${{ vars.DOCKERHUB_USERNAME }}/migraine_forecast/tags"
          echo ""
          echo "Docker Hub cleanup skipped (all tags preserved)"

